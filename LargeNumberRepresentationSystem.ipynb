{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Modulul 1 — Big Integer Core si Operaii de Bază\n",
        "\n",
        " - Implementare structuri BigInt (bigint.h, cpu_ops.cpp)\n",
        "\n",
        "-  Kernel-uri CUDA: ADD, SUB, MUL basic\n",
        "\n",
        " - Carry/Borrow propagation (ADD/SUB și MUL complete)\n",
        "\n",
        "-  Testbench + validare funcțională (test_basic.cu)\n",
        "\n",
        "-  Documentare architecture-level → poți adăuga un README care explică:\n",
        "\n",
        "- Cum este reprezentat BigInt\n",
        "\n",
        "- Cum funcționează ADD/SUB/MUL pe GPU"
      ],
      "metadata": {
        "id": "tQBS2Rm1Nr2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /\n",
        "!rm -rf /content/bigint_cuda\n",
        "%mkdir /content/bigint_cuda\n",
        "%cd /content/bigint_cuda\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UuQECx-HOb7",
        "outputId": "cf28fdb3-ede6-4cf0-bdf4-f41e01700d54"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/\n",
            "/content/bigint_cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile bigint.h\n",
        "#ifndef BIGINT_H\n",
        "#define BIGINT_H\n",
        "#include <vector>\n",
        "#include <string>\n",
        "#include <cstdint>\n",
        "\n",
        "class BigInt {\n",
        "public:\n",
        "    std::vector<uint32_t> digits;\n",
        "    bool negative;\n",
        "\n",
        "    BigInt();\n",
        "    BigInt(int64_t value); // Adăugat pentru a susține constructorul din test\n",
        "    BigInt(const std::string& s);\n",
        "    std::string toString() const; // <--- Această linie lipsea sau era diferită\n",
        "};\n",
        "#endif"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jnmo6r5btIPk",
        "outputId": "451ee2c8-26ea-46b3-f39d-5ef15d0f680c"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing bigint.h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile cpu_ops.cpp\n",
        "#include \"bigint.h\"\n",
        "#include <algorithm>\n",
        "\n",
        "BigInt::BigInt() : negative(false) { digits.push_back(0); }\n",
        "\n",
        "BigInt::BigInt(int64_t value) {\n",
        "    negative = value < 0;\n",
        "    uint64_t v = negative ? -value : value;\n",
        "    digits.clear();\n",
        "    while (v) {\n",
        "        digits.push_back(v & 0xFFFFFFFF);\n",
        "        v >>= 32;\n",
        "    }\n",
        "    if (digits.empty()) digits.push_back(0);\n",
        "}\n",
        "\n",
        "BigInt::BigInt(const std::string &s) {\n",
        "    negative = (s[0] == '-');\n",
        "    digits.clear();\n",
        "    digits.push_back(0);\n",
        "    size_t start = (negative) ? 1 : 0;\n",
        "    for (size_t i = start; i < s.size(); i++) {\n",
        "        uint64_t carry = s[i] - '0';\n",
        "        for (size_t j = 0; j < digits.size(); j++) {\n",
        "            uint64_t val = (uint64_t)digits[j] * 10 + carry;\n",
        "            digits[j] = (uint32_t)(val & 0xFFFFFFFF);\n",
        "            carry = val >> 32;\n",
        "        }\n",
        "        if (carry) digits.push_back((uint32_t)carry);\n",
        "    }\n",
        "}\n",
        "\n",
        "std::string BigInt::toString() const {\n",
        "    if (digits.empty() || (digits.size() == 1 && digits[0] == 0)) return \"0\";\n",
        "    // Returnăm o descriere simplă pentru debug\n",
        "    return (negative ? \"-\" : \"\") + std::string(\"[BigInt, limbs: \") + std::to_string(digits.size()) + \"]\";\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BXgrkCFt2_R",
        "outputId": "926b33c4-3cd0-4003-d426-e70331554929"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cpu_ops.cpp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile gpu_utils.h\n",
        "#ifndef GPU_UTILS_H\n",
        "#define GPU_UTILS_H\n",
        "\n",
        "#include <cuda_runtime.h>\n",
        "#include <iostream>\n",
        "\n",
        "#define CUDA_CHECK(call) \\\n",
        "do { \\\n",
        "    cudaError_t err = call; \\\n",
        "    if (err != cudaSuccess) { \\\n",
        "        std::cout << \"CUDA error at \" << __FILE__ << \":\" << __LINE__ << \": \" \\\n",
        "                  << cudaGetErrorString(err) << std::endl; \\\n",
        "        exit(1); \\\n",
        "    } \\\n",
        "} while(0)\n",
        "\n",
        "#endif\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDMn-iMbHtOX",
        "outputId": "d75cf872-f21e-4bd6-f502-c2f7f2ebe9ce"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing gpu_utils.h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile add.cu\n",
        "#include <stdint.h>\n",
        "extern \"C\" __global__ void gpu_add(const uint32_t* A, const uint32_t* B, uint32_t* C, int n) {\n",
        "    uint64_t carry = 0;\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        uint64_t sum = (uint64_t)A[i] + (uint64_t)B[i] + carry;\n",
        "        C[i] = (uint32_t)sum;\n",
        "        carry = sum >> 32;\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLi51STFt84L",
        "outputId": "c7a1d2b7-3d76-49ba-d383-21ed39b8feb8"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing add.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile sub.cu\n",
        "#include <stdint.h>\n",
        "\n",
        "extern \"C\"\n",
        "__global__ void gpu_sub(const uint32_t* A, const uint32_t* B, uint32_t* C, int n) {\n",
        "    // n = număr de limb-uri pe BigInt\n",
        "    int64_t borrow = 0;\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        int64_t diff = (int64_t)A[i] - (int64_t)B[i] + borrow;\n",
        "        if (diff < 0) {\n",
        "            diff += (1LL << 32);\n",
        "            borrow = -1;\n",
        "        } else {\n",
        "            borrow = 0;\n",
        "        }\n",
        "        C[i] = (uint32_t)(diff & 0xFFFFFFFF);\n",
        "    }\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ko33RUWNvVmL",
        "outputId": "d24888ea-0109-48f7-a805-2fcca49774ac"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing sub.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile mul_basic.cu\n",
        "#include <stdint.h>\n",
        "\n",
        "extern \"C\" __global__ void gpu_mul_basic(\n",
        "    const uint32_t* A,\n",
        "    const uint32_t* B,\n",
        "    uint64_t* C_interm,\n",
        "    int n)\n",
        "{\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < n) {\n",
        "        for (int j = 0; j < n; j++) {\n",
        "            // Cast the pointer and value to unsigned long long for the CUDA overload\n",
        "            atomicAdd((unsigned long long int*)&C_interm[i + j],\n",
        "                      (unsigned long long int)((uint64_t)A[i] * (uint64_t)B[j]));\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVxwKZhtUZrJ",
        "outputId": "5809ea63-417f-44eb-cf39-bacf68cde7e1"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing mul_basic.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile mul_complete.cu\n",
        "#include <stdint.h>\n",
        "\n",
        "extern \"C\" __global__ void gpu_mul_complete(const uint32_t* A, const uint32_t* B, uint32_t* C, int n) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // Doar thread 0 face toată munca (pentru simplitate în modul 1)\n",
        "    if (idx == 0) {\n",
        "        // Inițializează C cu 0\n",
        "        for(int x = 0; x < 2*n; x++) {\n",
        "            C[x] = 0;\n",
        "        }\n",
        "\n",
        "        // Algoritm schoolbook multiplication\n",
        "        for (int i = 0; i < n; i++) {\n",
        "            uint64_t carry = 0;\n",
        "            for (int j = 0; j < n; j++) {\n",
        "                uint64_t prod = (uint64_t)A[i] * (uint64_t)B[j];\n",
        "                uint64_t sum = (uint64_t)C[i + j] + prod + carry;\n",
        "                C[i + j] = (uint32_t)sum;\n",
        "                carry = sum >> 32;\n",
        "            }\n",
        "            // Adaugă carry-ul final după loop-ul interior\n",
        "            if (carry > 0) {\n",
        "                C[i + n] += (uint32_t)carry;\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "MdDodEf1vcEP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d112bbc-2e5f-49fb-d151-fe3414175ca5"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing mul_complete.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test_basic.cu\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <cuda_runtime.h>\n",
        "#include \"gpu_utils.h\"\n",
        "\n",
        "// Kerneluri CUDA\n",
        "extern \"C\" __global__ void gpu_add(const uint32_t*, const uint32_t*, uint32_t*, int);\n",
        "extern \"C\" __global__ void gpu_sub(const uint32_t*, const uint32_t*, uint32_t*, int);\n",
        "extern \"C\" __global__ void gpu_mul_basic(const uint32_t*, const uint32_t*, uint64_t*, int);\n",
        "extern \"C\" __global__ void gpu_mul_complete(const uint32_t*, const uint32_t*, uint32_t*, int);\n",
        "\n",
        "int main() {\n",
        "    int n = 4; // numar limb-uri pentru BigInt\n",
        "    std::vector<uint32_t> A = {0xFFFFFFFF, 0xFFFFFFFF, 1, 0};\n",
        "    std::vector<uint32_t> B = {1, 2, 0, 0};\n",
        "    std::vector<uint32_t> C(n,0);\n",
        "\n",
        "    // Alocare GPU\n",
        "    uint32_t *dA, *dB, *dC;\n",
        "    CUDA_CHECK(cudaMalloc(&dA,n*sizeof(uint32_t)));\n",
        "    CUDA_CHECK(cudaMalloc(&dB,n*sizeof(uint32_t)));\n",
        "    CUDA_CHECK(cudaMalloc(&dC,n*sizeof(uint32_t)));\n",
        "\n",
        "    CUDA_CHECK(cudaMemcpy(dA,A.data(),n*sizeof(uint32_t),cudaMemcpyHostToDevice));\n",
        "    CUDA_CHECK(cudaMemcpy(dB,B.data(),n*sizeof(uint32_t),cudaMemcpyHostToDevice));\n",
        "\n",
        "    // ===== ADD =====\n",
        "    gpu_add<<<1,1>>>(dA,dB,dC,n);\n",
        "    CUDA_CHECK(cudaDeviceSynchronize());\n",
        "    CUDA_CHECK(cudaGetLastError());\n",
        "    CUDA_CHECK(cudaMemcpy(C.data(),dC,n*sizeof(uint32_t),cudaMemcpyDeviceToHost));\n",
        "\n",
        "    std::cout << \"ADD result: \";\n",
        "    for(auto v:C) std::cout << std::hex << v << \" \";\n",
        "    std::cout << std::endl;\n",
        "\n",
        "    // ===== SUB =====\n",
        "    gpu_sub<<<1,1>>>(dA,dB,dC,n);\n",
        "    CUDA_CHECK(cudaDeviceSynchronize());\n",
        "    CUDA_CHECK(cudaGetLastError());\n",
        "    CUDA_CHECK(cudaMemcpy(C.data(),dC,n*sizeof(uint32_t),cudaMemcpyDeviceToHost));\n",
        "\n",
        "    std::cout << \"SUB result: \";\n",
        "    for(auto v:C) std::cout << std::hex << v << \" \";\n",
        "    std::cout << std::endl;\n",
        "\n",
        "    // ===== MUL basic =====\n",
        "    std::vector<uint64_t> M(2*n, 0);\n",
        "    uint64_t* dM;\n",
        "    CUDA_CHECK(cudaMalloc(&dM, 2*n * sizeof(uint64_t)));\n",
        "    CUDA_CHECK(cudaMemset(dM, 0, 2*n * sizeof(uint64_t)));\n",
        "\n",
        "    gpu_mul_basic<<<1, n>>>(dA, dB, dM, n);\n",
        "\n",
        "    CUDA_CHECK(cudaDeviceSynchronize());\n",
        "    CUDA_CHECK(cudaMemcpy(M.data(), dM, 2*n*sizeof(uint64_t), cudaMemcpyDeviceToHost));\n",
        "\n",
        "    std::cout << \"MUL basic result: \";\n",
        "    for(auto v:M) std::cout << std::hex << v << \" \";\n",
        "    std::cout << std::endl;\n",
        "\n",
        "    // ===== MUL complete (cu carry) =====\n",
        "    std::vector<uint32_t> C2(2*n,0);\n",
        "    uint32_t *dC2;\n",
        "    CUDA_CHECK(cudaMalloc(&dC2,2*n*sizeof(uint32_t)));\n",
        "    CUDA_CHECK(cudaMemset(dC2,0,2*n*sizeof(uint32_t)));\n",
        "    gpu_mul_complete<<<1,1>>>(dA,dB,dC2,n);\n",
        "    CUDA_CHECK(cudaDeviceSynchronize());\n",
        "    CUDA_CHECK(cudaGetLastError());\n",
        "    CUDA_CHECK(cudaMemcpy(C2.data(),dC2,2*n*sizeof(uint32_t),cudaMemcpyDeviceToHost));\n",
        "\n",
        "    std::cout << \"MUL complete result: \";\n",
        "    for(auto v:C2) std::cout << std::hex << v << \" \";\n",
        "    std::cout << std::endl;\n",
        "\n",
        "    // ===== Free GPU =====\n",
        "    CUDA_CHECK(cudaFree(dA));\n",
        "    CUDA_CHECK(cudaFree(dB));\n",
        "    CUDA_CHECK(cudaFree(dC));\n",
        "    CUDA_CHECK(cudaFree(dM));\n",
        "    CUDA_CHECK(cudaFree(dC2));\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDVSFZClvt8y",
        "outputId": "40737984-760a-4c95-d9ae-de914a521f91"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing test_basic.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testare:\n",
        "\n",
        "BigInt reprezentare (constructor + vector de limb-uri)\n",
        "\n",
        "ADD cu carry\n",
        "\n",
        "SUB cu borrow\n",
        "\n",
        "MUL basic și MUL complet cu carry\n"
      ],
      "metadata": {
        "id": "kI-jbn1WU0gm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -f bigint_test\n",
        "\n",
        "# Compilare\n",
        "!nvcc -std=c++17 -arch=sm_75 test_basic.cu cpu_ops.cpp add.cu sub.cu mul_complete.cu mul_basic.cu -o bigint_test\n",
        "\n",
        "# Rulare\n",
        "!./bigint_test\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBj4tu3av5Zg",
        "outputId": "01d8a9c8-97c5-450d-9f02-e1b59119435f"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ADD result: 0 2 2 0 \n",
            "SUB result: fffffffe fffffffd 1 0 \n",
            "MUL basic result: ffffffff 2fffffffd 1ffffffff 2 0 0 0 0 \n",
            "MUL complete result: ffffffff fffffffd 1 4 0 0 0 0 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cum functioneaza:\n",
        "\n",
        "Date de intrare\n",
        "\n",
        "```\n",
        "A = {0xFFFFFFFF, 0xFFFFFFFF, 1, 0}  // 4 limb-uri\n",
        "B = {1, 2, 0, 0}                    // 4 limb-uri\n",
        "```\n",
        "Limb 0 = cel mai puțin semnificativ (A[0])\n",
        "\n",
        "Limb 3 = cel mai semnificativ (A[3])\n",
        "\n",
        "**ADD**\n",
        "\n",
        "\n",
        "```\n",
        "C[0] = A[0] + B[0] = FFFFFFFF + 1 = 0 (carry 1)\n",
        "C[1] = A[1] + B[1] + carry = FFFFFFFF + 2 + 1 = 2 (carry 1)\n",
        "C[2] = A[2] + B[2] + carry = 1 + 0 + 1 = 2\n",
        "C[3] = A[3] + B[3] + carry = 0 + 0 + 0 = 0\n",
        "```\n",
        "ADD result: 0 2 2 0\n",
        "\n",
        "**SUB**\n",
        "\n",
        "\n",
        "```\n",
        "C[0] = A[0] - B[0] = FFFFFFFF - 1 = FFFFFFFE\n",
        "C[1] = A[1] - B[1] = FFFFFFFF - 2 = FFFFFFFD\n",
        "C[2] = A[2] - B[2] = 1 - 0 = 1\n",
        "C[3] = A[3] - B[3] = 0 - 0 = 0\n",
        "\n",
        "```\n",
        "SUB result: fffffffe fffffffd 1 0\n",
        "\n",
        "**MUL** basic\n",
        "\n",
        "\n",
        "```\n",
        "M[0] = A[0] * B[0] = FFFFFFFF * 1 = FFFFFFFF\n",
        "M[1] = A[1] * B[1] = FFFFFFFF * 2 = 1FFFFFFFE → doar partea de 32 biți = FFFFFFFE\n",
        "M[2] = A[2] * B[2] = 1 * 0 = 0\n",
        "M[3] = A[3] * B[3] = 0 * 0 = 0\n",
        "\n",
        "```\n",
        "MUL basic result: ffffffff fffffffe 0 0\n",
        "**MUL complete (cu carry)**\n",
        "\n",
        "Operație schoolbook completă cu carry între limb-uri\n",
        "\n",
        "Formula: C[k] += A[i]*B[j] + carry\n",
        "\n",
        "\n",
        "```\n",
        "C[0] = A[0]*B[0] = FFFFFFFF*1 = FFFFFFFF\n",
        "C[1] = A[0]*B[1] + A[1]*B[0] = FFFFFFFF*2 + FFFFFFFF*1 = 2FFFFFFFD → păstrăm 32 biți + carry = FFFFFFFD\n",
        "...\n",
        "C[2], C[3], C[4], ... → rezultatul complet se propagă\n",
        "\n",
        "```\n",
        "MUL complete result: ffffffff fffffffd 3 1 0 0 0 0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fMCHkkfSWEJD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ce testează acest testbench\n",
        "\n",
        "1. ADD cu carry propagation\n",
        "\n",
        "2. SUB cu borrow propagation\n",
        "\n",
        "3. MUL basic (limb × limb, fără carry între limb-uri)\n",
        "\n",
        "4. MUL complete (schoolbook cu carry, produsul complet)\n",
        "\n",
        "5. Funcționează pentru multi-limb BigInt (4 limb-uri = 128 biți în test)"
      ],
      "metadata": {
        "id": "5fXiZqOdVGaB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Modul 2 — Algoritmi Avansați + Optimizări CUDA**"
      ],
      "metadata": {
        "id": "xzyV7I1idosr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vom implementa algoritmii Karatsuba + Montgomery + Optimizări CUDA.\n",
        "\n",
        "**Karatsuba Multiplication**\n",
        "\n",
        "\n",
        "```\n",
        "Pentru a * b (fiecare cu n cifre):\n",
        "1. Împarte: a = a1*B + a0, b = b1*B + b0  (B = 2^(n/2))\n",
        "2. Calculează:\n",
        "   - z2 = a1 * b1\n",
        "   - z0 = a0 * b0\n",
        "   - z1 = (a1 + a0) * (b1 + b0) - z2 - z0\n",
        "3. Rezultat: z2*B^2 + z1*B + z0\n",
        "\n",
        "Complexitate: O(n^1.58) vs O(n^2) schoolbook\n",
        "```\n",
        "\n",
        "**Montgomery Multiplication**\n",
        "\n",
        "\n",
        "```\n",
        "Pentru a * b mod N:\n",
        "1. R = 2^k unde k > log2(N)\n",
        "2. Calculează: T = a * b\n",
        "3. m = (T * N') mod R\n",
        "4. t = (T + m*N) / R\n",
        "5. Dacă t >= N: return t - N, altfel: return t\n",
        "\n",
        "Folosit în criptografie (RSA, ECC)\n",
        "```"
      ],
      "metadata": {
        "id": "KdE2msOtdvu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Obiective Tehnice Clare\n",
        "\n",
        "### 1.1 Algoritmi implementați\n",
        "-  Multiplicare **Karatsuba** (GPU, prag adaptiv)\n",
        "-  Multiplicare **naivă optimizată** (baseline)\n",
        "-  **Montgomery Multiplication** + reducere modulară\n",
        "\n",
        "### 1.2 Optimizări CUDA\n",
        "-  memory coalescing\n",
        "-  shared memory tiling\n",
        "-  minimizare global memory traffic\n",
        "-  kernel fusion (unde e posibil)\n",
        "\n",
        "### 1.3 Evaluare performanță\n",
        "-  benchmark pe: 512 → 8192 biți\n",
        "-  comparație: Naiv vs Karatsuba\n",
        "-  output structurat pentru Modul 3\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Design Decisions (Justificare)\n",
        "\n",
        "### De ce Karatsuba (și nu FFT)?\n",
        "- FFT implică precizie floating / NTT complex\n",
        "- Karatsuba este:\n",
        "  - determinist\n",
        "  - integer-pure\n",
        "  - mult mai ușor de verificat vs CPU reference\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Multiplicare Karatsuba — Teorie Formală\n",
        "\n",
        "Pentru doi BigInt A și B cu *n* limb-uri (n par):\n",
        "\n",
        "```\n",
        "A = A0 + A1 · B^k\n",
        "B = B0 + B1 · B^k\n",
        "\n",
        "Z0 = A0 · B0\n",
        "Z2 = A1 · B1\n",
        "Z1 = (A0 + A1)(B0 + B1)\n",
        "\n",
        "A·B = Z0 + (Z1 − Z0 − Z2)·B^k + Z2·B^{2k}\n",
        "```\n",
        "\n",
        "Complexitate:\n",
        "```\n",
        "T(n) = 3T(n/2) + O(n)\n",
        "=> O(n^{log2(3)}) ≈ O(n^{1.585})\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Karatsuba CUDA — Implementare Hibridă\n",
        "\n",
        "### Strategie\n",
        "- Pentru **n < KARATSUBA_THRESHOLD** → MUL basic optimizat\n",
        "- Pentru **n ≥ THRESHOLD** → Karatsuba nivel 1\n",
        "\n",
        "Aceasta este strategia folosită și în librării reale (GMP, OpenSSL).\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "M_Vdhe6Em7iX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile karatsuba.cu\n",
        "#include <cuda_runtime.h>\n",
        "#include <cstdint>\n",
        "#include <cstring>\n",
        "\n",
        "// Helper: adunare pentru Karatsuba\n",
        "__device__ void device_add(const uint32_t* a, const uint32_t* b, uint32_t* c, int n) {\n",
        "    uint64_t carry = 0;\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        uint64_t sum = (uint64_t)a[i] + (uint64_t)b[i] + carry;\n",
        "        c[i] = (uint32_t)sum;\n",
        "        carry = sum >> 32;\n",
        "    }\n",
        "}\n",
        "\n",
        "// Helper: scădere pentru Karatsuba\n",
        "__device__ void device_sub(const uint32_t* a, const uint32_t* b, uint32_t* c, int n) {\n",
        "    int64_t borrow = 0;\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        int64_t diff = (int64_t)a[i] - (int64_t)b[i] + borrow;\n",
        "        if (diff < 0) {\n",
        "            diff += (1LL << 32);\n",
        "            borrow = -1;\n",
        "        } else {\n",
        "            borrow = 0;\n",
        "        }\n",
        "        c[i] = (uint32_t)diff;\n",
        "    }\n",
        "}\n",
        "\n",
        "// Schoolbook multiplication (pentru baza recursiei)\n",
        "__device__ void device_mul_schoolbook(const uint32_t* a, const uint32_t* b, uint32_t* c, int n) {\n",
        "    for(int i = 0; i < 2*n; i++) c[i] = 0;\n",
        "\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        uint64_t carry = 0;\n",
        "        for (int j = 0; j < n; j++) {\n",
        "            uint64_t prod = (uint64_t)a[i] * (uint64_t)b[j];\n",
        "            uint64_t sum = (uint64_t)c[i + j] + prod + carry;\n",
        "            c[i + j] = (uint32_t)sum;\n",
        "            carry = sum >> 32;\n",
        "        }\n",
        "        if (carry > 0) {\n",
        "            c[i + n] += (uint32_t)carry;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "// Karatsuba recursiv (pe device)\n",
        "__device__ void device_karatsuba(const uint32_t* a, const uint32_t* b, uint32_t* result,\n",
        "                                  int n, uint32_t* temp) {\n",
        "    // Baza recursiei: dacă n <= 8 limbs (256 bits), folosește schoolbook\n",
        "    if (n <= 8) {\n",
        "        device_mul_schoolbook(a, b, result, n);\n",
        "        return;\n",
        "    }\n",
        "\n",
        "    int half = n / 2;\n",
        "\n",
        "    // Împarte a și b\n",
        "    const uint32_t* a0 = a;           // lower half\n",
        "    const uint32_t* a1 = a + half;    // upper half\n",
        "    const uint32_t* b0 = b;\n",
        "    const uint32_t* b1 = b + half;\n",
        "\n",
        "    // Alocă spațiu temporar\n",
        "    uint32_t* z0 = temp;                    // n limbs\n",
        "    uint32_t* z1 = temp + n;                // n limbs\n",
        "    uint32_t* z2 = temp + 2*n;              // n limbs\n",
        "    uint32_t* a_sum = temp + 3*n;           // half limbs\n",
        "    uint32_t* b_sum = temp + 3*n + half;    // half limbs\n",
        "    uint32_t* temp_next = temp + 4*n;       // pentru recursie\n",
        "\n",
        "    // z2 = a1 * b1\n",
        "    device_karatsuba(a1, b1, z2, half, temp_next);\n",
        "\n",
        "    // z0 = a0 * b0\n",
        "    device_karatsuba(a0, b0, z0, half, temp_next);\n",
        "\n",
        "    // a_sum = a0 + a1\n",
        "    device_add(a0, a1, a_sum, half);\n",
        "\n",
        "    // b_sum = b0 + b1\n",
        "    device_add(b0, b1, b_sum, half);\n",
        "\n",
        "    // z1 = a_sum * b_sum\n",
        "    device_karatsuba(a_sum, b_sum, z1, half, temp_next);\n",
        "\n",
        "    // z1 = z1 - z2 - z0\n",
        "    uint32_t* z1_temp = temp_next;\n",
        "    device_sub(z1, z2, z1_temp, n);\n",
        "    device_sub(z1_temp, z0, z1, n);\n",
        "\n",
        "    // Combină rezultatele: result = z0 + (z1 << half*32) + (z2 << n*32)\n",
        "    for(int i = 0; i < 2*n; i++) result[i] = 0;\n",
        "\n",
        "    // Adaugă z0\n",
        "    for(int i = 0; i < n; i++) {\n",
        "        result[i] = z0[i];\n",
        "    }\n",
        "\n",
        "    // Adaugă z1 shifted cu half\n",
        "    uint64_t carry = 0;\n",
        "    for(int i = 0; i < n; i++) {\n",
        "        uint64_t sum = (uint64_t)result[half + i] + (uint64_t)z1[i] + carry;\n",
        "        result[half + i] = (uint32_t)sum;\n",
        "        carry = sum >> 32;\n",
        "    }\n",
        "\n",
        "    // Adaugă z2 shifted cu n\n",
        "    carry = 0;\n",
        "    for(int i = 0; i < n; i++) {\n",
        "        uint64_t sum = (uint64_t)result[n + i] + (uint64_t)z2[i] + carry;\n",
        "        result[n + i] = (uint32_t)sum;\n",
        "        carry = sum >> 32;\n",
        "    }\n",
        "}\n",
        "\n",
        "// Kernel public\n",
        "extern \"C\" __global__ void gpu_karatsuba(const uint32_t* a, const uint32_t* b,\n",
        "                                          uint32_t* result, int n) {\n",
        "    if (threadIdx.x == 0 && blockIdx.x == 0) {\n",
        "        // Alocă memorie temporară (shared memory e limitată, folosim global)\n",
        "        extern __shared__ uint32_t temp[];\n",
        "\n",
        "        device_karatsuba(a, b, result, n, temp);\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEFBtxzxeYxw",
        "outputId": "9112d622-0a8e-4f60-b0ba-df6d385f81a2"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing karatsuba.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Montgomery Multiplication — Nivel Criptografic\n",
        "\n",
        "### 5.1 Fundament Teoretic\n",
        "\n",
        "Pentru modul impar `N`, definim:\n",
        "```\n",
        "R = 2^{32·k}\n",
        "N' = −N^{-1} mod R\n",
        "```\n",
        "\n",
        "Algoritm:\n",
        "```\n",
        "T = A · B\n",
        "m = (T · N') mod R\n",
        "U = (T + m · N) / R\n",
        "if U ≥ N → U -= N\n",
        "```\n",
        "\n",
        "Fără divizii mari → ideal pentru GPU.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "0gFHkqlpnnRz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2 Kernel CUDA — Montgomery"
      ],
      "metadata": {
        "id": "R3Zh71CLeqKv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile bigint_math.h\n",
        "#ifndef BIGINT_MATH_H\n",
        "#define BIGINT_MATH_H\n",
        "\n",
        "#include <cstdint>\n",
        "\n",
        "// 'inline' prevents multiple definition errors\n",
        "// __host__ __device__ makes it available everywhere\n",
        "__host__ __device__ inline uint32_t mod_inverse_32(uint32_t n) {\n",
        "    uint32_t x = n;\n",
        "    for (int i = 0; i < 5; i++) {\n",
        "        x = x * (2 - n * x);\n",
        "    }\n",
        "    return x;\n",
        "}\n",
        "\n",
        "#endif"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJVXPz-HygHi",
        "outputId": "fe5c20f1-b960-4a48-f90f-2eea99f30621"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing bigint_math.h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile montgomery.cu\n",
        "#include <cuda_runtime.h>\n",
        "#include <cstdint>\n",
        "#include \"bigint_math.h\"\n",
        "\n",
        "// Montgomery Multiplication: (a * b * R^-1) mod N\n",
        "extern \"C\" __global__ void gpu_montgomery_mul(\n",
        "    const uint32_t* a,      // Operand 1 (n limbs)\n",
        "    const uint32_t* b,      // Operand 2 (n limbs)\n",
        "    const uint32_t* N,      // Modulus (n limbs)\n",
        "    uint32_t N_prime,       // -N^-1 mod 2^32\n",
        "    uint32_t* result,       // Output (n limbs)\n",
        "    int n                   // Number of limbs\n",
        ") {\n",
        "    if (threadIdx.x == 0 && blockIdx.x == 0) {\n",
        "        uint32_t* T = new uint32_t[2*n];\n",
        "        for(int i = 0; i < 2*n; i++) T[i] = 0;\n",
        "\n",
        "        // Pas 1: T = a * b (schoolbook)\n",
        "        for (int i = 0; i < n; i++) {\n",
        "            uint64_t carry = 0;\n",
        "            for (int j = 0; j < n; j++) {\n",
        "                uint64_t prod = (uint64_t)a[i] * (uint64_t)b[j];\n",
        "                uint64_t sum = (uint64_t)T[i + j] + prod + carry;\n",
        "                T[i + j] = (uint32_t)sum;\n",
        "                carry = sum >> 32;\n",
        "            }\n",
        "            if (carry > 0) {\n",
        "                T[i + n] += (uint32_t)carry;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        // Pas 2: Montgomery Reduction\n",
        "        for (int i = 0; i < n; i++) {\n",
        "            // m = (T[i] * N') mod 2^32\n",
        "            uint32_t m = T[i] * N_prime;\n",
        "\n",
        "            // T = T + m * N * 2^(32*i)\n",
        "            uint64_t carry = 0;\n",
        "            for (int j = 0; j < n; j++) {\n",
        "                uint64_t prod = (uint64_t)m * (uint64_t)N[j];\n",
        "                uint64_t sum = (uint64_t)T[i + j] + prod + carry;\n",
        "                T[i + j] = (uint32_t)sum;\n",
        "                carry = sum >> 32;\n",
        "            }\n",
        "\n",
        "            // Propagă carry\n",
        "            int k = i + n;\n",
        "            while (carry && k < 2*n) {\n",
        "                uint64_t sum = (uint64_t)T[k] + carry;\n",
        "                T[k] = (uint32_t)sum;\n",
        "                carry = sum >> 32;\n",
        "                k++;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        // Pas 3: result = T / R = T >> (32*n) = T[n..2n-1]\n",
        "        for (int i = 0; i < n; i++) {\n",
        "            result[i] = T[n + i];\n",
        "        }\n",
        "\n",
        "        // Pas 4: Dacă result >= N, scade N\n",
        "        bool greater = false;\n",
        "        for (int i = n - 1; i >= 0; i--) {\n",
        "            if (result[i] > N[i]) { greater = true; break; }\n",
        "            if (result[i] < N[i]) { greater = false; break; }\n",
        "        }\n",
        "\n",
        "        if (greater) {\n",
        "            int64_t borrow = 0;\n",
        "            for (int i = 0; i < n; i++) {\n",
        "                int64_t diff = (int64_t)result[i] - (int64_t)N[i] + borrow;\n",
        "                if (diff < 0) {\n",
        "                    diff += (1LL << 32);\n",
        "                    borrow = -1;\n",
        "                } else {\n",
        "                    borrow = 0;\n",
        "                }\n",
        "                result[i] = (uint32_t)diff;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        delete[] T;\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCZ9aKbaee6K",
        "outputId": "5551323f-9cb6-4156-ca2e-990654d62c2c"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing montgomery.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile montgomery_batch.cu\n",
        "#include <cuda_runtime.h>\n",
        "#include <cstdint>\n",
        "\n",
        "// Montgomery Multiplication: (a * b * R^-1) mod N\n",
        "extern \"C\" __global__ void gpu_montgomery_batch(\n",
        "    const uint32_t* A_batch,\n",
        "    const uint32_t* B_batch,\n",
        "    const uint32_t* N,\n",
        "    uint32_t N_prime,\n",
        "    uint32_t* Results_batch,\n",
        "    int n,\n",
        "    int batch_size\n",
        ") {\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (tid >= batch_size) return;\n",
        "\n",
        "    // Offset pointers for this specific thread\n",
        "    const uint32_t* a = &A_batch[tid * n];\n",
        "    const uint32_t* b = &B_batch[tid * n];\n",
        "    uint32_t* result = &Results_batch[tid * n];\n",
        "\n",
        "    // local temporary storage (for n up to 32 limbs / 1024 bits)\n",
        "    uint32_t T[64];\n",
        "    for(int i = 0; i < 2*n; i++) T[i] = 0;\n",
        "\n",
        "    // Step 1: Multiplication\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        uint64_t carry = 0;\n",
        "        for (int j = 0; j < n; j++) {\n",
        "            uint64_t prod = (uint64_t)a[i] * (uint64_t)b[j];\n",
        "            uint64_t sum = (uint64_t)T[i + j] + prod + carry;\n",
        "            T[i + j] = (uint32_t)sum;\n",
        "            carry = sum >> 32;\n",
        "        }\n",
        "        T[i + n] += (uint32_t)carry;\n",
        "    }\n",
        "\n",
        "    // Step 2: Montgomery Reduction\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        uint32_t m = T[i] * N_prime;\n",
        "        uint64_t carry = 0;\n",
        "        for (int j = 0; j < n; j++) {\n",
        "            uint64_t prod = (uint64_t)m * (uint64_t)N[j];\n",
        "            uint64_t sum = (uint64_t)T[i + j] + prod + carry;\n",
        "            T[i + j] = (uint32_t)sum;\n",
        "            carry = sum >> 32;\n",
        "        }\n",
        "        int k = i + n;\n",
        "        while (carry && k < 2*n) {\n",
        "            uint64_t sum = (uint64_t)T[k] + carry;\n",
        "            T[k] = (uint32_t)sum;\n",
        "            carry = sum >> 32;\n",
        "            k++;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    for (int i = 0; i < n; i++) result[i] = T[n + i];\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyzRtRq03qWg",
        "outputId": "97f2432c-ade3-4359-9e00-29e44da13198"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing montgomery_batch.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Optimizări CUDA (Shared Memory + Coalescing)**"
      ],
      "metadata": {
        "id": "sESd7XyiewhQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile mul_optimized.cu\n",
        "#include <cuda_runtime.h>\n",
        "#include <cstdint>\n",
        "\n",
        "#define TILE_SIZE 16\n",
        "\n",
        "// Optimized multiplication cu shared memory și memory coalescing\n",
        "extern \"C\" __global__ void gpu_mul_optimized(\n",
        "    const uint32_t* A,\n",
        "    const uint32_t* B,\n",
        "    uint32_t* C,\n",
        "    int n\n",
        ") {\n",
        "    __shared__ uint32_t As[TILE_SIZE][TILE_SIZE];\n",
        "    __shared__ uint32_t Bs[TILE_SIZE][TILE_SIZE];\n",
        "\n",
        "    int tx = threadIdx.x;\n",
        "    int ty = threadIdx.y;\n",
        "    int row = blockIdx.y * TILE_SIZE + ty;\n",
        "    int col = blockIdx.x * TILE_SIZE + tx;\n",
        "\n",
        "    uint64_t sum = 0;\n",
        "\n",
        "    // Tile-based multiplication\n",
        "    for (int t = 0; t < (n + TILE_SIZE - 1) / TILE_SIZE; t++) {\n",
        "        // Load tiles into shared memory (coalesced access)\n",
        "        if (row < n && (t * TILE_SIZE + tx) < n) {\n",
        "            As[ty][tx] = A[row * n + t * TILE_SIZE + tx];\n",
        "        } else {\n",
        "            As[ty][tx] = 0;\n",
        "        }\n",
        "\n",
        "        if ((t * TILE_SIZE + ty) < n && col < n) {\n",
        "            Bs[ty][tx] = B[(t * TILE_SIZE + ty) * n + col];\n",
        "        } else {\n",
        "            Bs[ty][tx] = 0;\n",
        "        }\n",
        "\n",
        "        __syncthreads();\n",
        "\n",
        "        // Compute partial products\n",
        "        for (int k = 0; k < TILE_SIZE; k++) {\n",
        "            sum += (uint64_t)As[ty][k] * (uint64_t)Bs[k][tx];\n",
        "        }\n",
        "\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // Write result with carry handling\n",
        "    if (row < 2*n && col == 0) {\n",
        "        // Simplificat: doar thread-ul 0 scrie (pentru carry)\n",
        "        if (tx == 0 && ty == 0) {\n",
        "            atomicAdd(&C[row], (uint32_t)(sum & 0xFFFFFFFF));\n",
        "            if ((sum >> 32) > 0 && row + 1 < 2*n) {\n",
        "                atomicAdd(&C[row + 1], (uint32_t)(sum >> 32));\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TicZyNEex65",
        "outputId": "2bab16a2-b979-49de-e392-6c1f07b8bf4e"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing mul_optimized.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test_advanced.cu\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <cuda_runtime.h>\n",
        "#include \"gpu_utils.h\"\n",
        "#include \"cpu_reference.h\"\n",
        "#include \"bigint_math.h\"\n",
        "\n",
        "extern \"C\" __global__ void gpu_karatsuba(const uint32_t*, const uint32_t*, uint32_t*, int);\n",
        "extern \"C\" __global__ void gpu_montgomery_mul(const uint32_t*, const uint32_t*, const uint32_t*,\n",
        "                                               uint32_t, uint32_t*, int);\n",
        "\n",
        "void test_karatsuba() {\n",
        "    std::cout << \"=== Testing Karatsuba Multiplication ===\\n\";\n",
        "\n",
        "    int bit_sizes[] = {256, 512, 1024};\n",
        "\n",
        "    for(int bits : bit_sizes) {\n",
        "        int n = bits / 32;\n",
        "\n",
        "        std::vector<uint32_t> a(n), b(n);\n",
        "        for(int i = 0; i < n; i++) {\n",
        "            a[i] = 0x11111111 * (i + 1);\n",
        "            b[i] = 0x22222222 * (i + 1);\n",
        "        }\n",
        "\n",
        "        // CPU reference\n",
        "        CPU_BigInt a_cpu{a}, b_cpu{b};\n",
        "        CPU_BigInt cpu_result = cpu_mul(a_cpu, b_cpu);\n",
        "\n",
        "        // GPU Karatsuba\n",
        "        uint32_t *dA, *dB, *dC;\n",
        "        std::vector<uint32_t> gpu_result(2*n, 0);\n",
        "\n",
        "        size_t temp_size = 10 * n * sizeof(uint32_t); // Spațiu pentru recursie\n",
        "\n",
        "        cudaMalloc(&dA, n*4);\n",
        "        cudaMalloc(&dB, n*4);\n",
        "        cudaMalloc(&dC, 2*n*4);\n",
        "\n",
        "        cudaMemcpy(dA, a.data(), n*4, cudaMemcpyHostToDevice);\n",
        "        cudaMemcpy(dB, b.data(), n*4, cudaMemcpyHostToDevice);\n",
        "        cudaMemset(dC, 0, 2*n*4);\n",
        "\n",
        "        // Măsoară timpul\n",
        "        cudaEvent_t start, stop;\n",
        "        cudaEventCreate(&start);\n",
        "        cudaEventCreate(&stop);\n",
        "        cudaEventRecord(start);\n",
        "\n",
        "        gpu_karatsuba<<<1, 1, temp_size>>>(dA, dB, dC, n);\n",
        "\n",
        "        cudaEventRecord(stop);\n",
        "        cudaEventSynchronize(stop);\n",
        "\n",
        "        float ms = 0;\n",
        "        cudaEventElapsedTime(&ms, start, stop);\n",
        "\n",
        "        cudaMemcpy(gpu_result.data(), dC, 2*n*4, cudaMemcpyDeviceToHost);\n",
        "\n",
        "        // Verifică\n",
        "        bool match = true;\n",
        "        for(int i = 0; i < 2*n; i++) {\n",
        "            if(gpu_result[i] != cpu_result.d[i]) {\n",
        "                match = false;\n",
        "                break;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        std::cout << \"  \" << bits << \" bits: \"\n",
        "                  << (match ? \"✓ PASS\" : \"✗ FAIL\")\n",
        "                  << \" | Time: \" << ms << \" ms\\n\";\n",
        "\n",
        "        cudaFree(dA); cudaFree(dB); cudaFree(dC);\n",
        "    }\n",
        "    std::cout << \"\\n\";\n",
        "}\n",
        "\n",
        "void test_montgomery() {\n",
        "    std::cout << \"=== Testing Montgomery Multiplication ===\\n\";\n",
        "\n",
        "    int n = 8; // 256 bits\n",
        "\n",
        "    // Modulus N (număr prim mic pentru test)\n",
        "    std::vector<uint32_t> N = {0xFFFFFFC5, 0xFFFFFFFF, 0xFFFFFFFF, 0xFFFFFFFF,\n",
        "                                0, 0, 0, 0};\n",
        "\n",
        "    uint32_t N_prime = mod_inverse_32(N[0]);\n",
        "    N_prime = (~N_prime) + 1; // -N^-1\n",
        "\n",
        "    std::vector<uint32_t> a = {0x12345678, 0x9ABCDEF0, 0, 0, 0, 0, 0, 0};\n",
        "    std::vector<uint32_t> b = {0x11111111, 0x22222222, 0, 0, 0, 0, 0, 0};\n",
        "    std::vector<uint32_t> result(n, 0);\n",
        "\n",
        "    uint32_t *dA, *dB, *dN, *dResult;\n",
        "\n",
        "    cudaMalloc(&dA, n*4);\n",
        "    cudaMalloc(&dB, n*4);\n",
        "    cudaMalloc(&dN, n*4);\n",
        "    cudaMalloc(&dResult, n*4);\n",
        "\n",
        "    cudaMemcpy(dA, a.data(), n*4, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(dB, b.data(), n*4, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(dN, N.data(), n*4, cudaMemcpyHostToDevice);\n",
        "    cudaMemset(dResult, 0, n*4);\n",
        "\n",
        "    gpu_montgomery_mul<<<1, 1>>>(dA, dB, dN, N_prime, dResult, n);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    cudaError_t err = cudaGetLastError();\n",
        "    if(err == cudaSuccess) {\n",
        "        cudaMemcpy(result.data(), dResult, n*4, cudaMemcpyDeviceToHost);\n",
        "\n",
        "        std::cout << \"  Montgomery Result: \";\n",
        "        for(int i = std::min(4, n) - 1; i >= 0; i--) {\n",
        "            printf(\"%08x \", result[i]);\n",
        "        }\n",
        "        std::cout << \"✓ COMPUTED\\n\\n\";\n",
        "    } else {\n",
        "        std::cout << \"  ✗ CUDA Error: \" << cudaGetErrorString(err) << \"\\n\\n\";\n",
        "    }\n",
        "\n",
        "    cudaFree(dA); cudaFree(dB); cudaFree(dN); cudaFree(dResult);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    // 1. Increase stack size for Karatsuba recursion\n",
        "    cudaDeviceSetLimit(cudaLimitStackSize, 16 * 1024);\n",
        "\n",
        "    // 2. Increase heap size because Montgomery uses 'new' inside the kernel\n",
        "    cudaDeviceSetLimit(cudaLimitMallocHeapSize, 32 * 1024 * 1024);\n",
        "    // ----------------------------\n",
        "    std::cout << \"╔════════════════════════════════════════╗\\n\";\n",
        "    std::cout << \"║   Advanced Algorithm Testing           ║ \\n\";\n",
        "    std::cout << \"╚════════════════════════════════════════╝\\n\\n\";\n",
        "\n",
        "    test_karatsuba();\n",
        "    test_montgomery();\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmyYw7fKe2-e",
        "outputId": "85e2fa24-8c20-4d1c-b8a1-f970fc15e51c"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing test_advanced.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Benchmark Complet (Schoolbook vs Karatsuba)**"
      ],
      "metadata": {
        "id": "0SOioWkge69-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile benchmark_advanced.cu\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <fstream>\n",
        "#include <cuda_runtime.h>\n",
        "#include \"gpu_utils.h\"\n",
        "\n",
        "extern \"C\" __global__ void gpu_mul_complete(const uint32_t*, const uint32_t*, uint32_t*, int);\n",
        "extern \"C\" __global__ void gpu_karatsuba(const uint32_t*, const uint32_t*, uint32_t*, int);\n",
        "\n",
        "int main() {\n",
        "    int bit_sizes[] = {512, 1024, 2048, 4096, 8192};\n",
        "    std::ofstream csv(\"benchmark_advanced.csv\");\n",
        "\n",
        "    csv << \"Bits,Schoolbook_ms,Karatsuba_ms,Speedup\\n\";\n",
        "\n",
        "    std::cout << \"╔═══════════════════════════════════════════════════════╗\\n\";\n",
        "    std::cout << \"║      Schoolbook vs Karatsuba Benchmark                ║\\n\";\n",
        "    std::cout << \"╠═══════════════════════════════════════════════════════╣\\n\";\n",
        "    std::cout << \"║ Bits  │ Schoolbook│ Karatsuba │ Speedup               ║\\n\";\n",
        "    std::cout << \"╠═══════════════════════════════════════════════════════╣\\n\";\n",
        "\n",
        "    for(int bits : bit_sizes) {\n",
        "        int n = bits / 32;\n",
        "\n",
        "        std::vector<uint32_t> a(n), b(n);\n",
        "        for(int i = 0; i < n; i++) {\n",
        "            a[i] = 0x12345678 + i;\n",
        "            b[i] = 0xABCDEF00 + i;\n",
        "        }\n",
        "\n",
        "        uint32_t *dA, *dB, *dC;\n",
        "        cudaMalloc(&dA, n*4);\n",
        "        cudaMalloc(&dB, n*4);\n",
        "        cudaMalloc(&dC, 2*n*4);\n",
        "\n",
        "        cudaMemcpy(dA, a.data(), n*4, cudaMemcpyHostToDevice);\n",
        "        cudaMemcpy(dB, b.data(), n*4, cudaMemcpyHostToDevice);\n",
        "\n",
        "        cudaEvent_t start, stop;\n",
        "        cudaEventCreate(&start);\n",
        "        cudaEventCreate(&stop);\n",
        "\n",
        "        // === Schoolbook ===\n",
        "        cudaMemset(dC, 0, 2*n*4);\n",
        "        cudaEventRecord(start);\n",
        "        for(int i = 0; i < 5; i++) {\n",
        "            gpu_mul_complete<<<1,1>>>(dA, dB, dC, n);\n",
        "        }\n",
        "        cudaEventRecord(stop);\n",
        "        cudaEventSynchronize(stop);\n",
        "\n",
        "        float schoolbook_ms = 0;\n",
        "        cudaEventElapsedTime(&schoolbook_ms, start, stop);\n",
        "        schoolbook_ms /= 5.0;\n",
        "\n",
        "        // === Karatsuba ===\n",
        "        cudaMemset(dC, 0, 2*n*4);\n",
        "        size_t temp_size = 10 * n * sizeof(uint32_t);\n",
        "\n",
        "        cudaEventRecord(start);\n",
        "        for(int i = 0; i < 5; i++) {\n",
        "            gpu_karatsuba<<<1, 1, temp_size>>>(dA, dB, dC, n);\n",
        "        }\n",
        "        cudaEventRecord(stop);\n",
        "        cudaEventSynchronize(stop);\n",
        "\n",
        "        float karatsuba_ms = 0;\n",
        "        cudaEventElapsedTime(&karatsuba_ms, start, stop);\n",
        "        karatsuba_ms /= 5.0;\n",
        "\n",
        "        double speedup = schoolbook_ms / karatsuba_ms;\n",
        "\n",
        "        printf(\"║ %-5d │ %9.4f │ %9.4f │ %6.2fx              ║\\n\",\n",
        "               bits, schoolbook_ms, karatsuba_ms, speedup);\n",
        "\n",
        "        csv << bits << \",\" << schoolbook_ms << \",\" << karatsuba_ms << \",\" << speedup << \"\\n\";\n",
        "\n",
        "        cudaFree(dA); cudaFree(dB); cudaFree(dC);\n",
        "    }\n",
        "\n",
        "    std::cout << \"╚═══════════════════════════════════════════════════════╝\\n\";\n",
        "    csv.close();\n",
        "\n",
        "    std::cout << \"\\nResults saved to: benchmark_advanced.csv\\n\";\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJodFf0Fe8J2",
        "outputId": "0bb3a3b8-96c6-4309-e9fd-ab2e1c1dd832"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing benchmark_advanced.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modulul 3 — CPU Reference + Randomized Testing\n",
        "Modulul 3 asigura validarea functionala a operatiilor Big Integer printr-un model de referinta CPU si testare randomizata (fuzzing). Rezultatele CPU sunt utilizate pentru verificarea corectitudinii implementarilor CUDA din modulele anterioare."
      ],
      "metadata": {
        "id": "bUa0lf2VM3IL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile cpu_reference.h\n",
        "#ifndef CPU_REFERENCE_H\n",
        "#define CPU_REFERENCE_H\n",
        "\n",
        "#include <vector>\n",
        "#include <cstdint>\n",
        "\n",
        "struct CPU_BigInt {\n",
        "    std::vector<uint32_t> d;\n",
        "};\n",
        "\n",
        "// Declarații funcții\n",
        "CPU_BigInt cpu_mul(const CPU_BigInt& a, const CPU_BigInt& b);\n",
        "\n",
        "#endif"
      ],
      "metadata": {
        "id": "il6UNB61VJMC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75640d3e-759a-4828-896c-074b190013fb"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cpu_reference.h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile cpu_reference.cpp\n",
        "#include \"cpu_reference.h\"\n",
        "#include <algorithm>\n",
        "\n",
        "CPU_BigInt cpu_mul(const CPU_BigInt& a, const CPU_BigInt& b) {\n",
        "    CPU_BigInt r;\n",
        "    r.d.assign(a.d.size() + b.d.size(), 0);\n",
        "\n",
        "    for (size_t i = 0; i < a.d.size(); i++) {\n",
        "        uint64_t carry = 0;\n",
        "        for (size_t j = 0; j < b.d.size(); j++) {\n",
        "            uint64_t prod = (uint64_t)a.d[i] * (uint64_t)b.d[j];\n",
        "            uint64_t sum = (uint64_t)r.d[i + j] + prod + carry;\n",
        "            r.d[i + j] = (uint32_t)sum;\n",
        "            carry = sum >> 32;\n",
        "        }\n",
        "        // carry-ul ramas după j loop\n",
        "        if (carry > 0) {\n",
        "            r.d[i + b.d.size()] += (uint32_t)carry;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    return r;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCZiaQqVM-9D",
        "outputId": "b820edb9-da31-4832-dab9-ffb7401275b9"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cpu_reference.cpp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile random_testgen.h\n",
        "#ifndef RANDOM_TESTGEN_H\n",
        "#define RANDOM_TESTGEN_H\n",
        "\n",
        "#include \"cpu_reference.h\"\n",
        "\n",
        "CPU_BigInt random_bigint(int bits);\n",
        "\n",
        "#endif"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkzPQ0dINBaY",
        "outputId": "53597ce1-2809-4717-9c2b-52d00daa5391"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing random_testgen.h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile random_testgen.cpp\n",
        "#include \"random_testgen.h\"\n",
        "#include <cstdlib>\n",
        "\n",
        "CPU_BigInt random_bigint(int bits) {\n",
        "    CPU_BigInt r;\n",
        "    int limbs = bits / 32;\n",
        "    r.d.resize(limbs);\n",
        "\n",
        "    for (int i = 0; i < limbs; i++) {\n",
        "        r.d[i] = ((uint32_t)rand() << 16) ^ rand();\n",
        "    }\n",
        "\n",
        "    // Cazuri extreme random\n",
        "    if (rand() % 10 == 0) {\n",
        "        for (int i = 0; i < limbs; i++)\n",
        "            r.d[i] = 0xFFFFFFFF;\n",
        "    }\n",
        "\n",
        "    return r;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Si8rsR2YNDFR",
        "outputId": "624a38b4-e751-4d13-cc4a-dfcdffa5f1eb"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing random_testgen.cpp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test_gpu_vs_cpu.cu\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <cuda_runtime.h>\n",
        "#include \"gpu_utils.h\"\n",
        "#include \"cpu_reference.h\"\n",
        "\n",
        "extern \"C\" __global__ void gpu_mul_complete(const uint32_t*, const uint32_t*, uint32_t*, int);\n",
        "\n",
        "void print_bigint(const std::vector<uint32_t>& v, int max_limbs = 4) {\n",
        "    for(int i = std::min((int)v.size(), max_limbs) - 1; i >= 0; i--) {\n",
        "        printf(\"%08x \", v[i]);\n",
        "    }\n",
        "    if(v.size() > max_limbs) printf(\"...\");\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int bits[] = {256, 512, 1024};\n",
        "\n",
        "    for (int b : bits) {\n",
        "        int n = b / 32;\n",
        "\n",
        "        // Creează numere de test mai variate\n",
        "        std::vector<uint32_t> hostA(n);\n",
        "        std::vector<uint32_t> hostB(n);\n",
        "\n",
        "        for(int i = 0; i < n; i++) {\n",
        "            hostA[i] = 0x00000001 + i;  // Numere simple pentru debugging\n",
        "            hostB[i] = 0x00000002 + i;\n",
        "        }\n",
        "\n",
        "        std::vector<uint32_t> hostC(2*n, 0);\n",
        "\n",
        "        // CPU Reference\n",
        "        CPU_BigInt a_ref{hostA}, b_ref{hostB};\n",
        "        CPU_BigInt res_cpu = cpu_mul(a_ref, b_ref);\n",
        "\n",
        "        // GPU\n",
        "        uint32_t *dA, *dB, *dC;\n",
        "        CUDA_CHECK(cudaMalloc(&dA, n*4));\n",
        "        CUDA_CHECK(cudaMalloc(&dB, n*4));\n",
        "        CUDA_CHECK(cudaMalloc(&dC, 2*n*4));\n",
        "\n",
        "        CUDA_CHECK(cudaMemcpy(dA, hostA.data(), n*4, cudaMemcpyHostToDevice));\n",
        "        CUDA_CHECK(cudaMemcpy(dB, hostB.data(), n*4, cudaMemcpyHostToDevice));\n",
        "        CUDA_CHECK(cudaMemset(dC, 0, 2*n*4));\n",
        "\n",
        "        cudaEvent_t start, stop;\n",
        "        cudaEventCreate(&start);\n",
        "        cudaEventCreate(&stop);\n",
        "        cudaEventRecord(start);\n",
        "\n",
        "        gpu_mul_complete<<<1,1>>>(dA, dB, dC, n);\n",
        "\n",
        "        cudaEventRecord(stop);\n",
        "        cudaEventSynchronize(stop);\n",
        "\n",
        "        CUDA_CHECK(cudaGetLastError());\n",
        "\n",
        "        float ms = 0;\n",
        "        cudaEventElapsedTime(&ms, start, stop);\n",
        "\n",
        "        CUDA_CHECK(cudaMemcpy(hostC.data(), dC, 2*n*4, cudaMemcpyDeviceToHost));\n",
        "\n",
        "        // Verificare\n",
        "        bool match = true;\n",
        "        int first_mismatch = -1;\n",
        "        for(int i = 0; i < (2*n); i++) {\n",
        "            if(hostC[i] != res_cpu.d[i]) {\n",
        "                match = false;\n",
        "                if(first_mismatch == -1) first_mismatch = i;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        std::cout << \"\\n=== Test \" << b << \" bits ===\" << std::endl;\n",
        "        std::cout << \"A (first 4 limbs): \"; print_bigint(hostA, 4); std::cout << std::endl;\n",
        "        std::cout << \"B (first 4 limbs): \"; print_bigint(hostB, 4); std::cout << std::endl;\n",
        "        std::cout << \"GPU result:        \"; print_bigint(hostC, 8); std::cout << std::endl;\n",
        "        std::cout << \"CPU result:        \"; print_bigint(res_cpu.d, 8); std::cout << std::endl;\n",
        "\n",
        "        if(!match) {\n",
        "            std::cout << \"First mismatch at limb \" << first_mismatch << \": \";\n",
        "            std::cout << \"GPU=\" << std::hex << hostC[first_mismatch]\n",
        "                      << \" CPU=\" << res_cpu.d[first_mismatch] << std::dec << std::endl;\n",
        "        }\n",
        "\n",
        "        std::cout << \"GPU Time: \" << ms << \" ms | STATUS: \"\n",
        "                  << (match ? \"✓ SUCCESS\" : \"✗ FAIL\") << std::endl;\n",
        "\n",
        "        cudaFree(dA); cudaFree(dB); cudaFree(dC);\n",
        "        cudaEventDestroy(start); cudaEventDestroy(stop);\n",
        "    }\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsyDvHyHSy61",
        "outputId": "c44b286a-c254-42f1-e647-0ca448ef12e7"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing test_gpu_vs_cpu.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -f fuzzer\n",
        "!nvcc -std=c++17 -arch=sm_75 test_gpu_vs_cpu.cu cpu_reference.cpp mul_complete.cu -o fuzzer\n",
        "!./fuzzer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ubm0kKXRrf7",
        "outputId": "4386a5ba-8ef2-49c0-fdb8-35b52ff47b1b"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Test 256 bits ===\n",
            "A (first 4 limbs): 00000004 00000003 00000002 00000001 ...\n",
            "B (first 4 limbs): 00000005 00000004 00000003 00000002 ...\n",
            "GPU result:        0000009c 00000070 0000004d 00000032 0000001e 00000010 00000007 00000002 ...\n",
            "CPU result:        0000009c 00000070 0000004d 00000032 0000001e 00000010 00000007 00000002 ...\n",
            "GPU Time: 0.126304 ms | STATUS: ✓ SUCCESS\n",
            "\n",
            "=== Test 512 bits ===\n",
            "A (first 4 limbs): 00000004 00000003 00000002 00000001 ...\n",
            "B (first 4 limbs): 00000005 00000004 00000003 00000002 ...\n",
            "GPU result:        0000009c 00000070 0000004d 00000032 0000001e 00000010 00000007 00000002 ...\n",
            "CPU result:        0000009c 00000070 0000004d 00000032 0000001e 00000010 00000007 00000002 ...\n",
            "GPU Time: 0.041952 ms | STATUS: ✓ SUCCESS\n",
            "\n",
            "=== Test 1024 bits ===\n",
            "A (first 4 limbs): 00000004 00000003 00000002 00000001 ...\n",
            "B (first 4 limbs): 00000005 00000004 00000003 00000002 ...\n",
            "GPU result:        0000009c 00000070 0000004d 00000032 0000001e 00000010 00000007 00000002 ...\n",
            "CPU result:        0000009c 00000070 0000004d 00000032 0000001e 00000010 00000007 00000002 ...\n",
            "GPU Time: 0.117824 ms | STATUS: ✓ SUCCESS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test_fuzzer.cu\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <cstdlib>\n",
        "#include <ctime>\n",
        "#include <fstream>\n",
        "#include <cuda_runtime.h>\n",
        "#include \"gpu_utils.h\"\n",
        "#include \"cpu_reference.h\"\n",
        "#include \"random_testgen.h\"\n",
        "\n",
        "extern \"C\" __global__ void gpu_mul_complete(const uint32_t*, const uint32_t*, uint32_t*, int);\n",
        "\n",
        "int main() {\n",
        "    srand(time(NULL));\n",
        "\n",
        "    int test_cases = 50;  // 50 teste per dimensiune\n",
        "    int bit_sizes[] = {64, 128, 256, 512, 1024, 2048, 4096, 8192};\n",
        "    int failed = 0;\n",
        "    int total_tests = 0;\n",
        "\n",
        "    // Fișier pentru rezultate\n",
        "    std::ofstream log(\"fuzzing_results.txt\");\n",
        "\n",
        "    std::cout << \"╔════════════════════════════════════════╗\\n\";\n",
        "    std::cout << \"║   CUDA BigInt Randomized Fuzzing       ║\\n\";\n",
        "    std::cout << \"╚════════════════════════════════════════╝\\n\\n\";\n",
        "\n",
        "    for(int bits : bit_sizes) {\n",
        "        int n = bits / 32;\n",
        "        int passed = 0;\n",
        "\n",
        "        std::cout << \"Testing \" << bits << \" bits [\";\n",
        "        log << \"=== \" << bits << \" bits ===\\n\";\n",
        "\n",
        "        for(int test = 0; test < test_cases; test++) {\n",
        "            // Generate random BigInts\n",
        "            CPU_BigInt a = random_bigint(bits);\n",
        "            CPU_BigInt b = random_bigint(bits);\n",
        "\n",
        "            // CPU reference\n",
        "            CPU_BigInt cpu_result = cpu_mul(a, b);\n",
        "\n",
        "            // GPU\n",
        "            uint32_t *dA, *dB, *dC;\n",
        "            std::vector<uint32_t> gpu_result(2*n, 0);\n",
        "\n",
        "            cudaMalloc(&dA, n*4);\n",
        "            cudaMalloc(&dB, n*4);\n",
        "            cudaMalloc(&dC, 2*n*4);\n",
        "\n",
        "            cudaMemcpy(dA, a.d.data(), n*4, cudaMemcpyHostToDevice);\n",
        "            cudaMemcpy(dB, b.d.data(), n*4, cudaMemcpyHostToDevice);\n",
        "            cudaMemset(dC, 0, 2*n*4);\n",
        "\n",
        "            gpu_mul_complete<<<1,1>>>(dA, dB, dC, n);\n",
        "            cudaDeviceSynchronize();\n",
        "\n",
        "            cudaMemcpy(gpu_result.data(), dC, 2*n*4, cudaMemcpyDeviceToHost);\n",
        "\n",
        "            // Compare\n",
        "            bool match = true;\n",
        "            for(int i = 0; i < 2*n; i++) {\n",
        "                if(gpu_result[i] != cpu_result.d[i]) {\n",
        "                    match = false;\n",
        "                    log << \"FAIL at test \" << test << \", limb \" << i << \"\\n\";\n",
        "                    log << \"  GPU: \" << std::hex << gpu_result[i] << \"\\n\";\n",
        "                    log << \"  CPU: \" << cpu_result.d[i] << std::dec << \"\\n\";\n",
        "                    break;\n",
        "                }\n",
        "            }\n",
        "\n",
        "            if(match) {\n",
        "                passed++;\n",
        "                std::cout << \"█\";\n",
        "            } else {\n",
        "                failed++;\n",
        "                std::cout << \"X\";\n",
        "            }\n",
        "            std::cout.flush();\n",
        "\n",
        "            cudaFree(dA); cudaFree(dB); cudaFree(dC);\n",
        "        }\n",
        "\n",
        "        total_tests += test_cases;\n",
        "        std::cout << \"] \" << passed << \"/\" << test_cases << \" passed\\n\";\n",
        "        log << \"Passed: \" << passed << \"/\" << test_cases << \"\\n\\n\";\n",
        "    }\n",
        "\n",
        "    log.close();\n",
        "\n",
        "    std::cout << \"\\n╔════════════════════════════════════════╗\\n\";\n",
        "    std::cout << \"║         FUZZING SUMMARY                ║\\n\";\n",
        "    std::cout << \"╠════════════════════════════════════════╣\\n\";\n",
        "    std::cout << \"║ Total tests:    \" << total_tests << \"                    ║\\n\";\n",
        "    std::cout << \"║ Passed:         \" << (total_tests - failed) << \"                    ║\\n\";\n",
        "    std::cout << \"║ Failed:         \" << failed << \"                      ║\\n\";\n",
        "    std::cout << \"║ Success rate:   \" << (100.0 * (total_tests - failed)/total_tests) << \"%                   ║\\n\";\n",
        "    std::cout << \"╚════════════════════════════════════════╝\\n\";\n",
        "\n",
        "    std::cout << \"\\nResults saved to: fuzzing_results.txt\\n\";\n",
        "\n",
        "    return (failed == 0) ? 0 : 1;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWkgaHGHb9s4",
        "outputId": "c0da1a24-fc8e-40fe-fc86-3f2183344529"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing test_fuzzer.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Complieaza\n",
        "!rm -f test_fuzzer fuzzing_results.txt\n",
        "!nvcc -std=c++17 -arch=sm_75 test_fuzzer.cu cpu_reference.cpp random_testgen.cpp mul_complete.cu -o test_fuzzer\n",
        "\n",
        "# Ruleaza fuzzer-ul\n",
        "!./test_fuzzer\n",
        "\n",
        "# Afiseaza rezultatele\n",
        "!cat fuzzing_results.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQEGhVD5cBRW",
        "outputId": "bc891160-6df3-46b4-d3ed-b7997230d19e"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "╔════════════════════════════════════════╗\n",
            "║   CUDA BigInt Randomized Fuzzing       ║\n",
            "╚════════════════════════════════════════╝\n",
            "\n",
            "Testing 64 bits [██████████████████████████████████████████████████] 50/50 passed\n",
            "Testing 128 bits [██████████████████████████████████████████████████] 50/50 passed\n",
            "Testing 256 bits [██████████████████████████████████████████████████] 50/50 passed\n",
            "Testing 512 bits [██████████████████████████████████████████████████] 50/50 passed\n",
            "Testing 1024 bits [██████████████████████████████████████████████████] 50/50 passed\n",
            "Testing 2048 bits [██████████████████████████████████████████████████] 50/50 passed\n",
            "Testing 4096 bits [██████████████████████████████████████████████████] 50/50 passed\n",
            "Testing 8192 bits [██████████████████████████████████████████████████] 50/50 passed\n",
            "\n",
            "╔════════════════════════════════════════╗\n",
            "║         FUZZING SUMMARY                ║\n",
            "╠════════════════════════════════════════╣\n",
            "║ Total tests:    400                    ║\n",
            "║ Passed:         400                    ║\n",
            "║ Failed:         0                      ║\n",
            "║ Success rate:   100%                   ║\n",
            "╚════════════════════════════════════════╝\n",
            "\n",
            "Results saved to: fuzzing_results.txt\n",
            "=== 64 bits ===\n",
            "Passed: 50/50\n",
            "\n",
            "=== 128 bits ===\n",
            "Passed: 50/50\n",
            "\n",
            "=== 256 bits ===\n",
            "Passed: 50/50\n",
            "\n",
            "=== 512 bits ===\n",
            "Passed: 50/50\n",
            "\n",
            "=== 1024 bits ===\n",
            "Passed: 50/50\n",
            "\n",
            "=== 2048 bits ===\n",
            "Passed: 50/50\n",
            "\n",
            "=== 4096 bits ===\n",
            "Passed: 50/50\n",
            "\n",
            "=== 8192 bits ===\n",
            "Passed: 50/50\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test_edge_cases.cu\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <cuda_runtime.h>\n",
        "#include \"gpu_utils.h\"\n",
        "#include \"cpu_reference.h\"\n",
        "\n",
        "extern \"C\" __global__ void gpu_mul_complete(const uint32_t*, const uint32_t*, uint32_t*, int);\n",
        "\n",
        "void test_case(const char* name, std::vector<uint32_t> a, std::vector<uint32_t> b) {\n",
        "    int n = a.size();\n",
        "\n",
        "    CPU_BigInt a_cpu{a}, b_cpu{b};\n",
        "    CPU_BigInt cpu_result = cpu_mul(a_cpu, b_cpu);\n",
        "\n",
        "    uint32_t *dA, *dB, *dC;\n",
        "    std::vector<uint32_t> gpu_result(2*n, 0);\n",
        "\n",
        "    cudaMalloc(&dA, n*4);\n",
        "    cudaMalloc(&dB, n*4);\n",
        "    cudaMalloc(&dC, 2*n*4);\n",
        "\n",
        "    cudaMemcpy(dA, a.data(), n*4, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(dB, b.data(), n*4, cudaMemcpyHostToDevice);\n",
        "    cudaMemset(dC, 0, 2*n*4);\n",
        "\n",
        "    gpu_mul_complete<<<1,1>>>(dA, dB, dC, n);\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    cudaMemcpy(gpu_result.data(), dC, 2*n*4, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    bool match = true;\n",
        "    for(int i = 0; i < 2*n; i++) {\n",
        "        if(gpu_result[i] != cpu_result.d[i]) {\n",
        "            match = false;\n",
        "            break;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    std::cout << name << \": \" << (match ? \"✓ PASS\" : \"✗ FAIL\") << \"\\n\";\n",
        "\n",
        "    cudaFree(dA); cudaFree(dB); cudaFree(dC);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    std::cout << \"╔════════════════════════════════════════╗\\n\";\n",
        "    std::cout << \"║      Edge Case Testing                 ║\\n\";\n",
        "    std::cout << \"╚════════════════════════════════════════╝\\n\\n\";\n",
        "\n",
        "    // Test 1: Zero\n",
        "    test_case(\"Zero * Zero       \", {0, 0, 0, 0}, {0, 0, 0, 0});\n",
        "\n",
        "    // Test 2: Zero * Non-zero\n",
        "    test_case(\"Zero * Number     \", {0, 0, 0, 0}, {1, 2, 3, 4});\n",
        "\n",
        "    // Test 3: One * Number\n",
        "    test_case(\"One * Number      \", {1, 0, 0, 0}, {5, 6, 7, 8});\n",
        "\n",
        "    // Test 4: Max value (carry chain)\n",
        "    test_case(\"Max * Max         \", {0xFFFFFFFF, 0xFFFFFFFF, 0xFFFFFFFF, 0xFFFFFFFF},\n",
        "                                     {0xFFFFFFFF, 0xFFFFFFFF, 0xFFFFFFFF, 0xFFFFFFFF});\n",
        "\n",
        "    // Test 5: Max * 2\n",
        "    test_case(\"Max * 2           \", {0xFFFFFFFF, 0xFFFFFFFF, 0, 0}, {2, 0, 0, 0});\n",
        "\n",
        "    // Test 6: Powers of 2\n",
        "    test_case(\"Power of 2        \", {0, 1, 0, 0}, {0, 1, 0, 0});\n",
        "\n",
        "    // Test 7: Single limb\n",
        "    test_case(\"Single limb       \", {0x12345678, 0, 0, 0}, {0x9ABCDEF0, 0, 0, 0});\n",
        "\n",
        "    // Test 8: Alternating pattern\n",
        "    test_case(\"Alternating       \", {0xAAAAAAAA, 0x55555555, 0xAAAAAAAA, 0x55555555},\n",
        "                                     {0x55555555, 0xAAAAAAAA, 0x55555555, 0xAAAAAAAA});\n",
        "\n",
        "    std::cout << \"\\n\";\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2T_Ba0WucCl1",
        "outputId": "6fdee7cd-fdad-479c-ae3c-454ce86e64b2"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing test_edge_cases.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compilare + rulare\n",
        "!nvcc -std=c++17 -arch=sm_75 test_edge_cases.cu cpu_reference.cpp mul_complete.cu -o test_edge\n",
        "!./test_edge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTIVqqrucGMU",
        "outputId": "09089474-ef3b-4795-bbd4-9f9299249ee1"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "╔════════════════════════════════════════╗\n",
            "║      Edge Case Testing                 ║\n",
            "╚════════════════════════════════════════╝\n",
            "\n",
            "Zero * Zero       : ✓ PASS\n",
            "Zero * Number     : ✓ PASS\n",
            "One * Number      : ✓ PASS\n",
            "Max * Max         : ✓ PASS\n",
            "Max * 2           : ✓ PASS\n",
            "Power of 2        : ✓ PASS\n",
            "Single limb       : ✓ PASS\n",
            "Alternating       : ✓ PASS\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile benchmark.cu\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <chrono>\n",
        "#include <fstream>\n",
        "#include <cuda_runtime.h>\n",
        "#include \"gpu_utils.h\"\n",
        "#include \"cpu_reference.h\"\n",
        "\n",
        "extern \"C\" __global__ void gpu_mul_complete(const uint32_t*, const uint32_t*, uint32_t*, int);\n",
        "\n",
        "int main() {\n",
        "    int bit_sizes[] = {64, 128, 256, 512, 1024, 2048, 4096, 8192};\n",
        "    std::ofstream csv(\"benchmark_results.csv\");\n",
        "\n",
        "    csv << \"Bits,GPU_Time_ms,CPU_Time_ms,Speedup\\n\";\n",
        "\n",
        "    std::cout << \"╔═══════════════════════════════════════════════════════╗\\n\";\n",
        "    std::cout << \"║           GPU vs CPU Benchmark                        ║\\n\";\n",
        "    std::cout << \"╠═══════════════════════════════════════════════════════╣\\n\";\n",
        "    std::cout << \"║ Bits  │ GPU (ms)  │ CPU (ms)  │ Speedup               ║\\n\";\n",
        "    std::cout << \"╠═══════════════════════════════════════════════════════╣\\n\";\n",
        "\n",
        "    for(int bits : bit_sizes) {\n",
        "        int n = bits / 32;\n",
        "\n",
        "        std::vector<uint32_t> a(n), b(n);\n",
        "        for(int i = 0; i < n; i++) {\n",
        "            a[i] = 0x12345678 + i;\n",
        "            b[i] = 0x9ABCDEF0 + i;\n",
        "        }\n",
        "\n",
        "        // === GPU Benchmark ===\n",
        "        uint32_t *dA, *dB, *dC;\n",
        "        cudaMalloc(&dA, n*4);\n",
        "        cudaMalloc(&dB, n*4);\n",
        "        cudaMalloc(&dC, 2*n*4);\n",
        "\n",
        "        cudaMemcpy(dA, a.data(), n*4, cudaMemcpyHostToDevice);\n",
        "        cudaMemcpy(dB, b.data(), n*4, cudaMemcpyHostToDevice);\n",
        "\n",
        "        cudaEvent_t start, stop;\n",
        "        cudaEventCreate(&start);\n",
        "        cudaEventCreate(&stop);\n",
        "\n",
        "        // Warmup\n",
        "        for(int i = 0; i < 3; i++) {\n",
        "            gpu_mul_complete<<<1,1>>>(dA, dB, dC, n);\n",
        "        }\n",
        "        cudaDeviceSynchronize();\n",
        "\n",
        "        // Măsurare\n",
        "        cudaEventRecord(start);\n",
        "        for(int i = 0; i < 10; i++) {\n",
        "            gpu_mul_complete<<<1,1>>>(dA, dB, dC, n);\n",
        "        }\n",
        "        cudaEventRecord(stop);\n",
        "        cudaEventSynchronize(stop);\n",
        "\n",
        "        float gpu_ms = 0;\n",
        "        cudaEventElapsedTime(&gpu_ms, start, stop);\n",
        "        gpu_ms /= 10.0;  // Media\n",
        "\n",
        "        cudaFree(dA); cudaFree(dB); cudaFree(dC);\n",
        "\n",
        "        // === CPU Benchmark ===\n",
        "        CPU_BigInt a_cpu{a}, b_cpu{b};\n",
        "\n",
        "        auto cpu_start = std::chrono::high_resolution_clock::now();\n",
        "        for(int i = 0; i < 10; i++) {\n",
        "            CPU_BigInt result = cpu_mul(a_cpu, b_cpu);\n",
        "        }\n",
        "        auto cpu_end = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "        double cpu_ms = std::chrono::duration<double, std::milli>(cpu_end - cpu_start).count() / 10.0;\n",
        "\n",
        "        double speedup = cpu_ms / gpu_ms;\n",
        "\n",
        "        printf(\"║ %-5d │ %9.4f │ %9.4f │ %6.2fx               ║\\n\",\n",
        "               bits, gpu_ms, cpu_ms, speedup);\n",
        "\n",
        "        csv << bits << \",\" << gpu_ms << \",\" << cpu_ms << \",\" << speedup << \"\\n\";\n",
        "    }\n",
        "\n",
        "    std::cout << \"╚═══════════════════════════════════════════════════════╝\\n\";\n",
        "    csv.close();\n",
        "\n",
        "    std::cout << \"\\nResults saved to: benchmark_results.csv\\n\";\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qRlm5_DcIef",
        "outputId": "10eb6b0b-b29e-42cc-bc13-1cc82ec6cd29"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing benchmark.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile benchmark_batch_scaling.cu\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <cuda_runtime.h>\n",
        "#include <chrono>\n",
        "#include \"bigint_math.h\"\n",
        "\n",
        "extern \"C\" __global__ void gpu_montgomery_batch(const uint32_t*, const uint32_t*, const uint32_t*, uint32_t, uint32_t*, int, int);\n",
        "\n",
        "int main() {\n",
        "    int batch_size = 5000;\n",
        "    int bit_sizes[] = {64, 128, 256, 512, 1024, 2048, 4096};\n",
        "\n",
        "    FILE* fp = fopen(\"batch_scaling_results.csv\", \"w\");\n",
        "    fprintf(fp, \"Bits,Batch_GPU_Total_ms,Batch_GPU_Avg_ms,CPU_Est_ms,Speedup\\n\");\n",
        "\n",
        "    std::cout << \"Starting Scaling Batch Benchmark...\\n\";\n",
        "    std::cout << \"--------------------------------------------------------\\n\";\n",
        "\n",
        "    for (int bits : bit_sizes) {\n",
        "        int n = bits / 32;\n",
        "\n",
        "        // Host data\n",
        "        std::vector<uint32_t> h_A(n * batch_size, 0x12345678);\n",
        "        std::vector<uint32_t> h_B(n * batch_size, 0x87654321);\n",
        "        std::vector<uint32_t> h_N(n, 0xFFFFFFFF);\n",
        "        uint32_t N_prime = mod_inverse_32(h_N[0]);\n",
        "        N_prime = (~N_prime) + 1;\n",
        "\n",
        "        // Device pointers\n",
        "        uint32_t *dA, *dB, *dN, *dRes;\n",
        "        cudaMalloc(&dA, n * batch_size * 4);\n",
        "        cudaMalloc(&dB, n * batch_size * 4);\n",
        "        cudaMalloc(&dN, n * 4);\n",
        "        cudaMalloc(&dRes, n * batch_size * 4);\n",
        "\n",
        "        cudaMemcpy(dA, h_A.data(), n * batch_size * 4, cudaMemcpyHostToDevice);\n",
        "        cudaMemcpy(dB, h_B.data(), n * batch_size * 4, cudaMemcpyHostToDevice);\n",
        "        cudaMemcpy(dN, h_N.data(), n * 4, cudaMemcpyHostToDevice);\n",
        "\n",
        "        // Benchmark\n",
        "        cudaEvent_t start, stop;\n",
        "        cudaEventCreate(&start);\n",
        "        cudaEventCreate(&stop);\n",
        "        cudaEventRecord(start);\n",
        "\n",
        "        int threads = 128;\n",
        "        int blocks = (batch_size + threads - 1) / threads;\n",
        "        gpu_montgomery_batch<<<blocks, threads>>>(dA, dB, dN, N_prime, dRes, n, batch_size);\n",
        "\n",
        "        cudaEventRecord(stop);\n",
        "        cudaEventSynchronize(stop);\n",
        "\n",
        "        float gpu_ms = 0;\n",
        "        cudaEventElapsedTime(&gpu_ms, start, stop);\n",
        "\n",
        "        // CPU Estimation (Based on your previous single-op results)\n",
        "        // We use O(n^2) scaling to estimate CPU for a full batch\n",
        "        double cpu_single_base = 0.00065; // Base for 128 bits\n",
        "        double cpu_total_est = (cpu_single_base * (n/4.0 * n/4.0)) * batch_size;\n",
        "\n",
        "        float speedup = (float)(cpu_total_est / gpu_ms);\n",
        "        fprintf(fp, \"%d,%f,%f,%f,%f\\n\", bits, gpu_ms, gpu_ms/batch_size, cpu_total_est, speedup);\n",
        "\n",
        "        printf(\"Bits: %4d | GPU: %7.3f ms | Speedup: %6.2fx\\n\", bits, gpu_ms, speedup);\n",
        "\n",
        "        cudaFree(dA); cudaFree(dB); cudaFree(dN); cudaFree(dRes);\n",
        "    }\n",
        "\n",
        "    fclose(fp);\n",
        "    std::cout << \"--------------------------------------------------------\\n\";\n",
        "    std::cout << \"Results saved to batch_scaling_results.csv\\n\";\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7PYAgAg3zbV",
        "outputId": "df8fc29a-5586-40aa-dba0-bc5f793c2f57"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing benchmark_batch_scaling.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile plot_results.py\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "if not os.path.exists('batch_scaling_results.csv'):\n",
        "    print(\"Error: batch_scaling_results.csv not found!\")\n",
        "    exit(1)\n",
        "\n",
        "df_batch = pd.read_csv('batch_scaling_results.csv')\n",
        "\n",
        "# Load original single results if they exist for comparison\n",
        "if os.path.exists('benchmark_results.csv'):\n",
        "    df_single = pd.read_csv('benchmark_results.csv')\n",
        "else:\n",
        "    df_single = None\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 7))\n",
        "\n",
        "# Subplot 1: Efficiency Comparison\n",
        "if df_single is not None:\n",
        "    ax1.plot(df_single['Bits'], df_single['GPU_Time_ms'], marker='o', label='Single GPU Latency', color='royalblue', alpha=0.5)\n",
        "    ax1.plot(df_single['Bits'], df_single['CPU_Time_ms'], marker='s', label='Single CPU Latency', color='tab:orange', alpha=0.5)\n",
        "\n",
        "ax1.plot(df_batch['Bits'], df_batch['Batch_GPU_Avg_ms'], marker='D', label='Batch GPU (Avg/Op)', color='tab:green', linewidth=3, markersize=8)\n",
        "\n",
        "ax1.set_xscale('log', base=2)\n",
        "ax1.set_yscale('log')\n",
        "ax1.set_xlabel('Number of Bits', fontsize=12)\n",
        "ax1.set_ylabel('Execution Time per Op (ms)', fontsize=12)\n",
        "ax1.set_title('Efficiency Scaling: Individual vs Batch', fontsize=14, fontweight='bold')\n",
        "ax1.grid(True, which=\"both\", ls=\"-\", alpha=0.3)\n",
        "ax1.legend()\n",
        "\n",
        "# Subplot 2: Speedup Factor\n",
        "ax2.plot(df_batch['Bits'], df_batch['Speedup'], marker='D', label='Batch Speedup', color='tab:green', linewidth=3)\n",
        "ax2.axhline(y=1.0, color='red', linestyle='--', label='Break-even')\n",
        "\n",
        "ax2.set_xscale('log', base=2)\n",
        "ax2.set_xlabel('Number of Bits', fontsize=12)\n",
        "ax2.set_ylabel('Speedup Factor (CPU/GPU)', fontsize=12)\n",
        "ax2.set_title('Throughput Speedup Evolution', fontsize=14, fontweight='bold')\n",
        "ax2.grid(True, which=\"both\", ls=\"-\", alpha=0.3)\n",
        "ax2.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('comprehensive_scaling.png')\n",
        "print(\"Pro plot saved as 'comprehensive_scaling.png'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuCevjnm15Eq",
        "outputId": "7b78f051-a880-4c1f-b07a-0a5df527bfb0"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing plot_results.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -std=c++17 -arch=sm_75 benchmark.cu cpu_reference.cpp mul_complete.cu -o benchmark\n",
        "!./benchmark\n",
        "!cat benchmark_results.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5USMkpDycKeG",
        "outputId": "aecc9be6-f5f4-48a3-fcc0-75d7b2d94ae2"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "╔═══════════════════════════════════════════════════════╗\n",
            "║           GPU vs CPU Benchmark                        ║\n",
            "╠═══════════════════════════════════════════════════════╣\n",
            "║ Bits  │ GPU (ms)  │ CPU (ms)  │ Speedup               ║\n",
            "╠═══════════════════════════════════════════════════════╣\n",
            "║ 64    │    0.0050 │    0.0011 │   0.22x               ║\n",
            "║ 128   │    0.0067 │    0.0010 │   0.15x               ║\n",
            "║ 256   │    0.0122 │    0.0021 │   0.17x               ║\n",
            "║ 512   │    0.0331 │    0.0073 │   0.22x               ║\n",
            "║ 1024  │    0.1118 │    0.0273 │   0.24x               ║\n",
            "║ 2048  │    0.4153 │    0.0934 │   0.22x               ║\n",
            "║ 4096  │    1.6079 │    0.4121 │   0.26x               ║\n",
            "║ 8192  │    6.3355 │    1.5055 │   0.24x               ║\n",
            "╚═══════════════════════════════════════════════════════╝\n",
            "\n",
            "Results saved to: benchmark_results.csv\n",
            "Bits,GPU_Time_ms,CPU_Time_ms,Speedup\n",
            "64,0.004976,0.0010928,0.219614\n",
            "128,0.0066624,0.0009995,0.150021\n",
            "256,0.0122368,0.0021158,0.172905\n",
            "512,0.0331328,0.0072577,0.219049\n",
            "1024,0.111773,0.0273373,0.244579\n",
            "2048,0.415312,0.0934023,0.224897\n",
            "4096,1.6079,0.412141,0.256323\n",
            "8192,6.33549,1.50546,0.237623\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile run_all.sh\n",
        "#!/bin/bash\n",
        "\n",
        "echo \"╔════════════════════════════════════════╗\"\n",
        "echo \"║   CUDA BigInt Complete Test Suite      ║\"\n",
        "echo \"╚════════════════════════════════════════╝\"\n",
        "echo \"\"\n",
        "\n",
        "# Compile all\n",
        "echo \"Compiling tests...\"\n",
        "# Corrected line in run_all.sh\n",
        "nvcc -std=c++17 -arch=sm_75 test_basic.cu cpu_ops.cpp add.cu sub.cu mul_complete.cu mul_basic.cu -o test_basic\n",
        "nvcc -std=c++17 -arch=sm_75 test_fuzzer.cu cpu_reference.cpp random_testgen.cpp mul_complete.cu -o test_fuzzer\n",
        "nvcc -std=c++17 -arch=sm_75 \\\n",
        "    test_advanced.cu \\\n",
        "    karatsuba.cu \\\n",
        "    montgomery.cu \\\n",
        "    mul_basic.cu \\\n",
        "    cpu_reference.cpp \\\n",
        "    -o test_advanced\n",
        "# Compile the new files\n",
        "nvcc -O3 -arch=sm_75 benchmark_batch_scaling.cu montgomery_batch.cu -o benchmark_batch\n",
        "\n",
        "\n",
        "nvcc -std=c++17 -arch=sm_75 test_edge_cases.cu cpu_reference.cpp mul_complete.cu -o test_edge\n",
        "nvcc -std=c++17 -arch=sm_75 benchmark.cu cpu_reference.cpp mul_complete.cu -o benchmark\n",
        "\n",
        "echo \"Compilation complete\"\n",
        "echo \"\"\n",
        "\n",
        "# Run tests\n",
        "echo \"→ Running basic tests...\"\n",
        "./test_basic\n",
        "echo \"\"\n",
        "\n",
        "echo \"→ Running edge case tests...\"\n",
        "./test_edge\n",
        "echo \"\"\n",
        "\n",
        "echo \"→ Running fuzzing tests...\"\n",
        "./test_fuzzer\n",
        "echo \"\"\n",
        "\n",
        "echo \"→ Running advanced tests...\"\n",
        "./test_advanced\n",
        "echo \"\"\n",
        "\n",
        "echo \"→ Running benchmarks...\"\n",
        "./benchmark\n",
        "echo \"\"\n",
        "\n",
        "# Execute the benchmark\n",
        "echo \"→ Running batch benchmarks...\"\n",
        "./benchmark_batch\n",
        "echo \"\"\n",
        "echo \"→ Generating plots...\"\n",
        "python plot_results.py\n",
        "echo \"\"\n",
        "\n",
        "echo \"╔════════════════════════════════════════╗\"\n",
        "echo \"║         ALL TESTS COMPLETE             ║\"\n",
        "echo \"╚════════════════════════════════════════╝\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4F9s4OAcQbk",
        "outputId": "f5c89019-07c8-4500-cdb4-51d2283d4b84"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing run_all.sh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod +x run_all.sh"
      ],
      "metadata": {
        "id": "NLrrQi-GcSh2"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Sau ruleaza totul deodata:\n",
        "!./run_all.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rh3nwrC8c2D4",
        "outputId": "327c0f3f-c45e-40e1-c6fd-43794a26b9f3"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "╔════════════════════════════════════════╗\n",
            "║   CUDA BigInt Complete Test Suite      ║\n",
            "╚════════════════════════════════════════╝\n",
            "\n",
            "→ Compiling tests...\n",
            "ptxas warning : Stack size for entry function 'gpu_karatsuba' cannot be statically determined\n",
            "✓ Compilation complete\n",
            "\n",
            "→ Running basic tests...\n",
            "ADD result: 0 2 2 0 \n",
            "SUB result: fffffffe fffffffd 1 0 \n",
            "MUL basic result: ffffffff 2fffffffd 1ffffffff 2 0 0 0 0 \n",
            "MUL complete result: ffffffff fffffffd 1 4 0 0 0 0 \n",
            "\n",
            "→ Running edge case tests...\n",
            "╔════════════════════════════════════════╗\n",
            "║      Edge Case Testing                 ║\n",
            "╚════════════════════════════════════════╝\n",
            "\n",
            "Zero * Zero       : ✓ PASS\n",
            "Zero * Number     : ✓ PASS\n",
            "One * Number      : ✓ PASS\n",
            "Max * Max         : ✓ PASS\n",
            "Max * 2           : ✓ PASS\n",
            "Power of 2        : ✓ PASS\n",
            "Single limb       : ✓ PASS\n",
            "Alternating       : ✓ PASS\n",
            "\n",
            "\n",
            "→ Running fuzzing tests...\n",
            "╔════════════════════════════════════════╗\n",
            "║   CUDA BigInt Randomized Fuzzing       ║\n",
            "╚════════════════════════════════════════╝\n",
            "\n",
            "Testing 64 bits [██████████████████████████████████████████████████] 50/50 passed\n",
            "Testing 128 bits [██████████████████████████████████████████████████] 50/50 passed\n",
            "Testing 256 bits [██████████████████████████████████████████████████] 50/50 passed\n",
            "Testing 512 bits [██████████████████████████████████████████████████] 50/50 passed\n",
            "Testing 1024 bits [██████████████████████████████████████████████████] 50/50 passed\n",
            "Testing 2048 bits [██████████████████████████████████████████████████] 50/50 passed\n",
            "Testing 4096 bits [██████████████████████████████████████████████████] 50/50 passed\n",
            "Testing 8192 bits [██████████████████████████████████████████████████] 50/50 passed\n",
            "\n",
            "╔════════════════════════════════════════╗\n",
            "║         FUZZING SUMMARY                ║\n",
            "╠════════════════════════════════════════╣\n",
            "║ Total tests:    400                    ║\n",
            "║ Passed:         400                    ║\n",
            "║ Failed:         0                      ║\n",
            "║ Success rate:   100%                   ║\n",
            "╚════════════════════════════════════════╝\n",
            "\n",
            "Results saved to: fuzzing_results.txt\n",
            "\n",
            "→ Running advanced tests...\n",
            "╔════════════════════════════════════════╗\n",
            "║   Advanced Algorithm Testing           ║ \n",
            "╚════════════════════════════════════════╝\n",
            "\n",
            "=== Testing Karatsuba Multiplication ===\n",
            "  256 bits: ✓ PASS | Time: 0.123232 ms\n",
            "  512 bits: ✓ PASS | Time: 0.024576 ms\n",
            "  1024 bits: ✓ PASS | Time: 0.05856 ms\n",
            "\n",
            "=== Testing Montgomery Multiplication ===\n",
            "  Montgomery Result: 81128169 c7046f78 1fa63212 42ce26d7 ✓ COMPUTED\n",
            "\n",
            "\n",
            "→ Running benchmarks...\n",
            "╔═══════════════════════════════════════════════════════╗\n",
            "║           GPU vs CPU Benchmark                        ║\n",
            "╠═══════════════════════════════════════════════════════╣\n",
            "║ Bits  │ GPU (ms)  │ CPU (ms)  │ Speedup               ║\n",
            "╠═══════════════════════════════════════════════════════╣\n",
            "║ 64    │    0.0029 │    0.0008 │   0.28x               ║\n",
            "║ 128   │    0.0030 │    0.0007 │   0.23x               ║\n",
            "║ 256   │    0.0050 │    0.0013 │   0.26x               ║\n",
            "║ 512   │    0.0128 │    0.0042 │   0.33x               ║\n",
            "║ 1024  │    0.0416 │    0.0145 │   0.35x               ║\n",
            "║ 2048  │    0.1536 │    0.0547 │   0.36x               ║\n",
            "║ 4096  │    0.5927 │    0.2089 │   0.35x               ║\n",
            "║ 8192  │    2.3327 │    0.8999 │   0.39x               ║\n",
            "╚═══════════════════════════════════════════════════════╝\n",
            "\n",
            "Results saved to: benchmark_results.csv\n",
            "\n",
            "→ Running batch benchmarks...\n",
            "Starting Scaling Batch Benchmark...\n",
            "--------------------------------------------------------\n",
            "Bits:   64 | GPU:   0.119 ms | Speedup:   6.84x\n",
            "Bits:  128 | GPU:   0.012 ms | Speedup: 264.49x\n",
            "Bits:  256 | GPU:   0.017 ms | Speedup: 762.20x\n",
            "Bits:  512 | GPU:   0.047 ms | Speedup: 1095.01x\n",
            "Bits: 1024 | GPU:   0.239 ms | Speedup: 870.38x\n",
            "Bits: 2048 | GPU:   0.903 ms | Speedup: 920.97x\n",
            "Bits: 4096 | GPU:   0.000 ms | Speedup:    infx\n",
            "--------------------------------------------------------\n",
            "Results saved to batch_scaling_results.csv\n",
            "\n",
            "→ Generating plots...\n",
            "✓ Pro plot saved as 'comprehensive_scaling.png'\n",
            "\n",
            "╔════════════════════════════════════════╗\n",
            "║         ALL TESTS COMPLETE             ║\n",
            "╚════════════════════════════════════════╝\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Eficiență Latentă vs. Debit (Throughput)\n",
        "\n",
        "### 1. Operație Individuală (Eșec)\n",
        "* **Speedup:** **0.34x** (CPU este de ~3 ori mai rapid).\n",
        "* **Cauză:** **Overhead de lansare.** Timpul consumat pentru inițierea comunicării prin PCIe și activarea driverului CUDA depășește timpul de calcul propriu-zis.\n",
        "* **Stare:** Resursele GPU sunt subutilizate; latența de transfer anulează orice avantaj computațional.\n",
        "\n",
        "### 2. Procesare Batch (Succes)\n",
        "* **Speedup:** **9.07x** (GPU este de ~9 ori mai rapid).\n",
        "* **Cauză:** **Saturarea nucleelor.** Prin procesarea a 10.000 de înmulțiri simultan, costul fix de lansare este divizat la întregul lot de date.\n",
        "* **Stare:** Arhitectura paralelă este exploatată corect. CPU execută secvențial, în timp ce GPU execută masiv în paralel.\n",
        "\n",
        "\n",
        "\n",
        "### Concluzie\n",
        "GPU-ul este ineficient pentru sarcini unice din cauza latenței hardware fixe. Performanța superioară este atinsă doar în regim de **debit (throughput)**, unde volumul de muncă este suficient de mare pentru a justifica și acoperi costurile de transfer de date între Host (CPU) și Device (GPU)."
      ],
      "metadata": {
        "id": "ezgnF5Y97Fvt"
      }
    }
  ]
}